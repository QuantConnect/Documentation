<p>
TensorFlow is a low-level library that we can use to implement machine learning algorithms. Unlike scikit, TensorFlow does not have any ready to use algorithms, Instead, TensorFlow provides the building blocks to implement the algorithms we need. TensorFlow is especially great for implement deep learning algorithms and working with large datasets since it allows us to take advantage of GPU's for training our models.
</p>

<h4> Preparing Data For Training and Testing </h4>

<p>
Let's create a neural network that predicts future prices given past prices. We'll build our network with TensorFlow and then train it using historical data. We can then test our model by visualizing its predictions against actual historical prices. First, we'll need to retrieve historical data for SPY.
</p>

<div class="section-example-container">
	<pre class="all">import tensorflow as tf

qb = QuantBook()
spy = qb.AddEquity("SPY").Symbol

# retrieve close data
data = qb.History(spy, 
                  datetime(2020, 6, 22), 
                  datetime(2020, 6, 27), 
                  Resolution.Minute).loc[spy].close</pre>
</div>

<p>
We'll feed our network the last 5 close prices to predict the next close. Let's format our data into our input dataframe X by offsetting our historical close prices.
</p>

<div class="section-example-container">
	<pre class="all"># Feeding 5 input past prices to predict the next price
lookback = 5
# Series to hold each set of input prices
lookback_series = []

# Offsetting close data by length of lookback
for i in range(1, lookback + 1):
    df = data.shift(i)[lookback:-1]
    df.name = f"close_-{i}"
    lookback_series.append(df)

# Formatting offset data into input format
X = pd.concat(lookback_series, axis=1).reset_index(drop=True)</pre>
</div>

<figure><img src="https://www.dropbox.com/s/1pqiats2jml4w2i/ml%201.PNG?dl=1" class="img-responsive">
	<figcaption>Linear Regression Model on SPY Data</figcaption>
</figure>

<p>
Since we'd like to predict the closing price of SPY 1 timestep into the future, we should create a dataframe containing this data. This will serve as our neural network's training and testing output Y.
</p>

<div class="section-example-container">
	<pre class="all"># Shift our time series close data by 1
Y = data.shift(-1)[lookback:-1].reset_index(drop=True)</pre>
</div>

<p>
We can then split our data into training and testing sets using scikit-learn's <code>train_test_split</code>. We will use the training set to train our model and then assess the network's predictions against the test data. Let's use a third of our data to test and the remaining to train our model.
</p>

<div class="section-example-container">
	<pre class="all"># import scikit-learn's train_test_split method
from sklearn.model_selection import train_test_split

# split historical data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, shuffle=False)</pre>
</div>

<h4> Building Models </h4>

<p>
Let's build a neural network with 3 hidden layers and an output layer. We'll have 32 neurons in our first layer, 16 in our second, and 8 in our third layer.
</p>

<div class="section-example-container">
	<pre class="all"># Initialize a tensorflow graph object
tf.reset_default_graph()
sess = tf.Session()

# parameters for our neural network
num_factors = X_test.shape[1]
num_neurons_1 = 32
num_neurons_2 = 16
num_neurons_3 = 8

# Placeholders for our inputs and outputs
X = tf.placeholder(dtype=tf.float32, shape=[None, num_factors], name='X')
Y = tf.placeholder(dtype=tf.float32, shape=[None])</pre>
</div>

<p>
Next, we can build our model layer by layer. We will need a set of weights and biases for each layer.
</p>

<div class="section-example-container">
	<pre class="all"># Initializers
weight_initializer = tf.variance_scaling_initializer(mode="fan_avg", distribution="uniform", scale=1)
bias_initializer = tf.zeros_initializer()

# Hidden weights
W_hidden_1 = tf.Variable(weight_initializer([num_factors, num_neurons_1]))
bias_hidden_1 = tf.Variable(bias_initializer([num_neurons_1]))
W_hidden_2 = tf.Variable(weight_initializer([num_neurons_1, num_neurons_2]))
bias_hidden_2 = tf.Variable(bias_initializer([num_neurons_2]))
W_hidden_3 = tf.Variable(weight_initializer([num_neurons_2, num_neurons_3]))
bias_hidden_3 = tf.Variable(bias_initializer([num_neurons_3]))

# Output weights
W_out = tf.Variable(weight_initializer([num_neurons_3, 1]))
bias_out = tf.Variable(bias_initializer([1]))

# Hidden layer
hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))
hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))
hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))

# Output layer
output = tf.transpose(tf.add(tf.matmul(hidden_3, W_out), bias_out), name='outer')</pre>
</div>

<h4> Training Models</h4>

<p>
We will need a loss function and an optimizer function to train our model; we can use TensorFlow's built-in <code>tf.squared_difference</code> and <code>tf.train.AdamOptimizer()</code>, respectively. An epoch is an iteration of our entire training set. Let's train our model for 20 epochs.
</p>

<div class="section-example-container">
	<pre class="all"> # Define loss and optimizer functions
loss = tf.reduce_mean(tf.squared_difference(output, Y))
optimizer = tf.train.AdamOptimizer().minimize(loss)
sess.run(tf.global_variables_initializer())

# Define training parameters
batch_size = len(y_train) // 10
epochs = 20

# Train Model
for _ in range(epochs):
    for i in range(0, len(y_train) // batch_size):
        start = i * batch_size
        batch_x = X_train[start:start + batch_size]
        batch_y = y_train[start:start + batch_size]
        sess.run(optimizer, feed_dict={X: batch_x, Y: batch_y}))</pre>
</div>

<h4> Testing Models </h4>

<p>
Finally, let's test how accurate our model is by plotting its predictions against actual price data.
</p>

<div class="section-example-container">
	<pre class="all">prediction = sess.run(output, feed_dict={X: X_test})
prediction = prediction.reshape(prediction.shape[1], 1)
y_test.reset_index(drop=True).plot(figsize=(16, 6), label="Actual")

# Plot predictions
plt.plot(prediction, label="Prediction")
plt.title("Test Set Results from Original Model")
plt.xlabel("Time step")
plt.ylabel("SPY Price")
plt.legend()
plt.show()</pre>
</div>

<figure><img src="https://www.dropbox.com/s/phs0fas1h7ppojh/ml%204.PNG?dl=1" class="img-responsive">
	<figcaption>Sequential Model's Predictions Against Actual </figcaption>
</figure>