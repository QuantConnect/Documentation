<script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<p>Outliers in a dataset can have large impacts on how models train. In some cases, you may leave outliers in a dataset because they can contain useful information. In other cases, you may want to transform the data to handle the outlier data points. There are several common methods to handle outliers.</p>

<h4>Winsorization Method</h4>
<p>The winsorization method removes outliers at the \(x\)% of the extremes. For example, if you winsorize at 1%, it removes the 1% of data points with the lowest value and the 1% of data points with the highest value. This threshold percentage is subjective, so it can result in overfitting.</p>

<h4>IQR Method</h4>
<p>The interquartile range method removes data points that fall outside of the interval \( [Q_1 - k (Q_3 - Q_1), Q_3 + k (Q_3 - Q_1)] \) for some constant \(k &gt;= 0\). This method can exclude up to 25% of observations on each side of the extremes. The interquartile range method doesn't work if the data is skewed or non-normal. Therefore, the disadvantage to this method is you need to review the factor distribution properties. If you need to, you can normalize the data with z-scores.</p>

\[Z = \frac{x - \mu}{\sigma}\]


<h4>Factor Ranking Method</h4>
<p>The factor ranking method ranks the data values instead of taking their raw values. With this method, you don't need to remove any outlier data points. This method transforms the data into a uniform distribution. After converting the data to a uniform distribution, Wang et al. (2014) perform an inverse normal transformation to make the factor values normally distributed. Wang et al. (2014) found this ranking technique outperforms the z-score transformation, suggesting that the distance between factor scores doesn't add useful information.</p>