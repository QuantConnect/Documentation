<p>In this example, a support vector regression prediction model using the following features and labels will be trained:</p>

<table class="qc-table table">
    <thead>
        <tr>
            <th>Data Category</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Features</td>
            <td>Daily percent change of the open, high, low, close, and volume of the SPY over the last 5 days</td>
        </tr>
        <tr>
            <td>Labels</td>
            <td>Daily percent return of the SPY over the next day</td>
        </tr>
    </tbody>
</table>

<p>The following image shows the time difference between the features and labels:</p>
<img class="docs-image" src="https://cdn.quantconnect.com/i/tu/ml-keras-function.png">

<p>Follow these steps to create a method to train your model:</p>

<h4>History Call</h4>
<p>You need historical data to train the model. Call <code>History</code> with <code>Symbol</code>, timerule, and resolution to obtain historical data. In this example, 2 years of daily trade bar data is used.</p>
<div class="section-example-container">
    <pre class="python">self.History(self.spy, 252*2, Resolution.Daily)</pre>
</div>

<h4>Prepare Data</h4>
<p>Follow the below steps to create a method to prepare the data for training and prediction.</p>
<ol>
    <li>Create a method to process the data for the algorithm class, with input data and number of timestep as arguments.</li>
    <div class="section-example-container">
        <pre class="python">def ProcessData(self, history, n_steps=5):</pre>
    </div>

    <li>Call the <code>pct_change</code> and <code>dropna</code> methods.</li>
    <div class="section-example-container">
        <pre class="python">    daily_pct_change = history.pct_change().dropna()</pre>
    </div>

    <li>Loop through the <code>daily_pct_change</code> DataFrame and collect the features and labels.</li>
    <div class="section-example-container">
        <pre class="python">    features = []
    labels = []
    for i in range(len(daily_pct_change)-n_steps):
        features.append(daily_pct_change.iloc[i:i+n_steps].values.flatten())
        labels.append(daily_pct_change['close'].iloc[i+n_steps])</pre>
    </div>

    <li>Convert the lists of features and labels into <code>numpy</code> arrays and return them.</li>
    <div class="section-example-container">
        <pre class="python">    features = np.array(features)
    labels = np.array(labels)

    return features, labels</pre>
    </div>
</ol>

<h4>Build and Fit Model</h4>
<p>Follow the below steps to build and fit the model.</p>
<ol>
    <li>Get processed training data.</li>
    <div class="section-example-container">
        <pre class="python">features, labels = self.ProcessData(history)</pre>
    </div>

    <li>Set the choices of hyperparameters used for grid search testing.</li>
    <div class="section-example-container">
        <pre class="python">param_grid = {'C': [.05, .1, .5, 1, 5, 10], 
              'epsilon': [0.001, 0.005, 0.01, 0.05, 0.1], 
              'gamma': ['auto', 'scale']}</pre>
    </div>

    <li>Call the <code>GridSearchCV</code> constructor with the SVR model, the parameter grid, a scoring method, the number of cross-validation folds.</li>
    <div class="section-example-container">
        <pre class="python">gsc = GridSearchCV(SVR(), param_grid, scoring='neg_mean_squared_error', cv=5)</pre>
    </div>

    <li>Call the <code>fit</code> method and then select the best estimator as the model. Save that as a class variable.</li>
    <div class="section-example-container">
        <pre class="python">self.model = gsc.fit(features, labels).best_estimator_</pre>
    </div>
</ol>