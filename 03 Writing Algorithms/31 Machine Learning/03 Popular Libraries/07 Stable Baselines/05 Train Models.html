<p>You can train the model at the beginning of your algorithm and you can periodically re-train it as the algorithm executes.</p>

<h4>Warm Up Training Data</h4>
<p>You need historical data to initially train the model at the start of your algorithm. To get the initial training data, in the <code class="csharp">Initialize</code><code class="python">initialize</code> method, make a <a href="https://www.quantconnect.com/docs/v2/writing-algorithms/historical-data/history-requests">history request</a>.</p>
<div class="section-example-container">
    <pre class="python">training_length = 252*2
self.training_data = RollingWindow[TradeBar](training_length)
history = self.history[TradeBar](self.spy, training_length, Resolution.DAILY)
for trade_bar in history:
    self.training_data.add(trade_bar)</pre>
</div>

<h4>Define a Training Method</h4>
<p>To train the model, define a method that fits the model with the training data.</p>
<div class="section-example-container">
    <pre class="python">def get_observations_and_rewards(self, n_step=5):
    training_df = self.pandas_converter.get_data_frame[TradeBar](list(self.training_data)[::-1])
    daily_pct_change = training_df['close'].pct_change().dropna()

    obs = []
    rewards = []
    for i in range(len(daily_pct_change)-n_step):
        obs.append(training_df.iloc[i:i+n_step].values)
        rewards.append(float(daily_pct_change.iloc[i+n_step]))
    obs = np.array(obs)
    rewards = np.array(rewards)

    return obs, rewards

def my_training_method(self):
    obs, rewards = self.get_observations_and_rewards()
    self.env = TradingEnv(obs, rewards)
    self.model = DQN("MlpPolicy", self.env)
    self.model.learn(total_timesteps=500)</pre>
</div>

<h4>Set Training Schedule</h4>
<p>To train the model at the beginning of your algorithm, in the <code class="csharp">Initialize</code><code class="python">initialize</code> method, call the <code class="csharp">Train</code><code class="python">train</code> method.</p>
<div class="section-example-container">
    <pre class="python">self.train(self.my_training_method)</pre>
</div>
<p>To periodically re-train the model as your algorithm executes, in the <code class="csharp">Initialize</code><code class="python">initialize</code> method, call the <code class="csharp">Train</code><code class="python">train</code> method as a <a href="/docs/v2/writing-algorithms/scheduled-events">Scheduled Event</a>.</p>
<div class="section-example-container">
    <pre class="python"># Train the model every Sunday at 8:00 AM
self.train(self.date_rules.every(DayOfWeek.SUNDAY), self.time_rules.at(8, 0), self.my_training_method)</pre>
</div>

<h4>Update Training Data</h4>
<p>To update the training data as the algorithm executes, in the <code class="csharp">OnData</code><code class="python">on_data</code> method, add the current <code>TradeBar</code> to the <code>RollingWindow</code> that holds the training data.</p>
<div class="section-example-container">
    <pre class="python">def on_data(self, slice: Slice) -> None:
    if self._symbol in slice.Bars:
        self.training_data.Add(slice.Bars[self._symbol])</pre>
</div>