<p>
     During this part of the contribution process, you need to edit the <span class="public-directory-name">Lean.DataSource.&lt;vendorNameDatasetName&gt; / DataProcessing / process.sample.ipynb</span>&nbsp;file so it transforms and moves your raw data into the format and location the <a href="/docs/v2/lean-engine/contributions/datasets/defining-data-models">GetSource methods</a> expect. 
     The notebook should save all the data history to the <span class="public-directory-name">output</span> directory in your machine's root directory (for example, <span class="public-directory-name">C: / output</span>) and it should save a sample of the data history to the <span class="public-directory-name">Lean.DataSource.&lt;vendorNameDatasetName&gt; / output</span> directory.
</p>

<p>Follow these steps to set up the downloading and processing script for your dataset:</p>

<ol>
     <li>Change the structure of the <span class="public-directory-name">Lean.DataSource.&lt;vendorNameDatasetName&gt; / output</span> directory to match the path structure you defined in the <code>GetSource</code> methods (for example, <span class="public-directory-name">output / alternative / xyzairline / ticketsales</span>).</li>
     <li>In the <span class="public-directory-name">Lean.DataSource.&lt;vendorNameDatasetName&gt; / DataProcessing / process.sample.ipynb</span> file, add some code to time how long it takes to process the entire dataset and how long it takes to update the dataset with one day's worth of data.</li>
    <div class="highlight">You need this information for when you provide the <a href="/docs/v2/lean-engine/contributions/datasets/data-documentation">dataset documentation</a>. We need to know how long it takes to process your dataset so we can schedule its processing job.</div>
    <li>In the processing file, load the raw data from your source.</li>
    <p>You can fetch data from any of the following sources:</p>
    <table class="qc-table table">
       <thead>
          <tr>
             <th>Source</th>
             <th>Considerations</th>
          </tr>
       </thead>
       <tbody>
          <tr>
             <td>Local Files</td>
             <td>It can help to first copy the data into location.</td>
          </tr>
          <tr>
             <td>Remote API</td>
             <td>Stay within the rate limits. You can use the rate gate class.</td>
          </tr>
       </tbody>
    </table>

    <p>You should load and process the data period by period. Use the date range provided to the script to process the specific dates provided.</p>

    <li>If your dataset is for universe selection data and it's at a higher frequency than hour resolution, resample your data to hourly or daily resolution.<br></li>
    <li>If any of the following statements are true, skip the rest of the steps in this tutorial:</li>
    <ul>
        <li>Your dataset is not related to Equities.</li>
        <li>Your dataset is related to Equities and already includes the point-in-time tickers.</li>
    </ul>
    <p>If your dataset is related to Equities and your dataset doesn't account for ticker changes, the rest of the steps help you to adjust the tickers over the historical data so they are point-in-time.</p>
    <li>If you don't have the <a href="https://www.quantconnect.com/datasets/quantconnect-us-equity-security-master/cli">US Equity Security Master dataset</a>, <a href="https://www.quantconnect.com/contact">contact us</a>.</li>
    <li class="python">In the <span class="public-file-name">Lean.DataSource.&lt;vendorNameDatasetName&gt; / DataProcessing / Program.cs</span> file, remove the statements of the <code>Main</code> method</li>
    <li>In a terminal, compile the data processing project.</li>
    <div class="cli section-example-container">
        <pre>$ dotnet build .\DataProcessing\DataProcessing.csproj</pre>
    </div>
    <p>This step generates a file that the <code>CLRImports</code> library uses.</p>
    <li class="python">In the <span class="public-directory-name">Lean.DataSource.&lt;vendorNameDatasetName&gt; / DataProcessing / process.sample.ipynb</span> file, import the <code>CLRImports</code> library.</li>
    <div class="python section-example-container">
        <pre class="python">from CLRImports import *</pre>
    </div>
    <li>Create and initialize a map file provider.</li>
    <div class="section-example-container">
        <pre class="python">map_file_provider = LocalZipMapFileProvider()
map_file_provider.Initialize(DefaultDataProvider())<br></pre>
    </div>
    <li>Create a security identifier.</li>
    <div class="section-example-container">
        <pre class="python">sid = SecurityIdentifier.GenerateEquity(point_in_time_ticker,
    Market.USA, True, map_file_provider, csv_date)</pre>
    </div>
</ol>

<p>After you finish editing the <span class="public-file-name">process.sample.ipynb</span>&nbsp;script, run its cells to populate the <span class="public-directory-name">Lean.DataSource.&lt;vendorNameDatasetName&gt; / output</span> directory and the <span class="public-directory-name">output</span> directory in your machine's root directory.</p>

<div class="highlight">Note: The pull request you make at the end must contain sample data so we can review it and run the demonstration algorithms.</div>
